{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## 0. Configs"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [],
   "source": [
    "# HF_MODEL_NAME = \"huawei-noah/TinyBERT_General_4L_312D\"\n",
    "HF_MODEL_NAME = \"prajjwal1/bert-small\"\n",
    "MODELS_FOLDER = './models'\n",
    "MODEL_SAVE_NAME = None\n",
    "MODEL_LOAD_NAME = None\n",
    "USE_WANDB = True\n",
    "USE_CUSTOM_MODEL = True\n",
    "\n",
    "RS = 42  # Random state\n",
    "TRAIN_FRACTION = 0.9\n",
    "BATCH_SIZE = 16\n",
    "LEARNING_RATE = 3e-5\n",
    "EPOCHS = 5"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Data loading"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.1. Json to Dataframe"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [
    {
     "data": {
      "text/plain": "                         id                     title  \\\n0  5733be284776f41900661182  University_of_Notre_Dame   \n1  5733be284776f4190066117f  University_of_Notre_Dame   \n2  5733be284776f41900661180  University_of_Notre_Dame   \n3  5733be284776f41900661181  University_of_Notre_Dame   \n4  5733be284776f4190066117e  University_of_Notre_Dame   \n\n                                             context  \\\n0  Architecturally, the school has a Catholic cha...   \n1  Architecturally, the school has a Catholic cha...   \n2  Architecturally, the school has a Catholic cha...   \n3  Architecturally, the school has a Catholic cha...   \n4  Architecturally, the school has a Catholic cha...   \n\n                                            question  \\\n0  To whom did the Virgin Mary allegedly appear i...   \n1  What is in front of the Notre Dame Main Building?   \n2  The Basilica of the Sacred heart at Notre Dame...   \n3                  What is the Grotto at Notre Dame?   \n4  What sits on top of the Main Building at Notre...   \n\n                               answer_text  answer_start  answer_end  \n0               Saint Bernadette Soubirous           515         541  \n1                a copper statue of Christ           188         213  \n2                        the Main Building           279         296  \n3  a Marian place of prayer and reflection           381         420  \n4       a golden statue of the Virgin Mary            92         126  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>title</th>\n      <th>context</th>\n      <th>question</th>\n      <th>answer_text</th>\n      <th>answer_start</th>\n      <th>answer_end</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>5733be284776f41900661182</td>\n      <td>University_of_Notre_Dame</td>\n      <td>Architecturally, the school has a Catholic cha...</td>\n      <td>To whom did the Virgin Mary allegedly appear i...</td>\n      <td>Saint Bernadette Soubirous</td>\n      <td>515</td>\n      <td>541</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>5733be284776f4190066117f</td>\n      <td>University_of_Notre_Dame</td>\n      <td>Architecturally, the school has a Catholic cha...</td>\n      <td>What is in front of the Notre Dame Main Building?</td>\n      <td>a copper statue of Christ</td>\n      <td>188</td>\n      <td>213</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>5733be284776f41900661180</td>\n      <td>University_of_Notre_Dame</td>\n      <td>Architecturally, the school has a Catholic cha...</td>\n      <td>The Basilica of the Sacred heart at Notre Dame...</td>\n      <td>the Main Building</td>\n      <td>279</td>\n      <td>296</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>5733be284776f41900661181</td>\n      <td>University_of_Notre_Dame</td>\n      <td>Architecturally, the school has a Catholic cha...</td>\n      <td>What is the Grotto at Notre Dame?</td>\n      <td>a Marian place of prayer and reflection</td>\n      <td>381</td>\n      <td>420</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5733be284776f4190066117e</td>\n      <td>University_of_Notre_Dame</td>\n      <td>Architecturally, the school has a Catholic cha...</td>\n      <td>What sits on top of the Main Building at Notre...</td>\n      <td>a golden statue of the Virgin Mary</td>\n      <td>92</td>\n      <td>126</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the raw json\n",
    "url = 'training_set.json'\n",
    "with open(url, 'r') as file:\n",
    "    raw = json.load(file)['data']\n",
    "data = []\n",
    "for topic in raw:\n",
    "    for paragraph in topic['paragraphs']:\n",
    "        for question in paragraph['qas']:\n",
    "            assert len(question['answers']) == 1\n",
    "            answer = question['answers'][0]\n",
    "            data.append((\n",
    "                question['id'],\n",
    "                topic['title'],\n",
    "                paragraph['context'],\n",
    "                question['question'],\n",
    "                answer['text'],\n",
    "                answer['answer_start'],\n",
    "                answer['answer_start'] + len(answer['text']),\n",
    "            ))\n",
    "dataset = pd.DataFrame(data,\n",
    "                       columns=('id', 'title', 'context', 'question', 'answer_text', 'answer_start', 'answer_end'))\n",
    "dataset.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 87599 entries, 0 to 87598\n",
      "Data columns (total 7 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   id            87599 non-null  string\n",
      " 1   title         87599 non-null  string\n",
      " 2   context       87599 non-null  string\n",
      " 3   question      87599 non-null  string\n",
      " 4   answer_text   87599 non-null  string\n",
      " 5   answer_start  87599 non-null  Int64 \n",
      " 6   answer_end    87599 non-null  Int64 \n",
      "dtypes: Int64(2), string(5)\n",
      "memory usage: 4.8 MB\n"
     ]
    }
   ],
   "source": [
    "dataset: pd.DataFrame = dataset.apply(pd.to_numeric, errors='ignore').convert_dtypes()\n",
    "# NOTE: stripping makes the test in the next cell fail\n",
    "# dataset['context'] = dataset['context'].str.strip()\n",
    "# dataset['question'] = dataset['question'].str.strip()\n",
    "dataset.info()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST PASSED: answer-text == context[start:end]\n"
     ]
    }
   ],
   "source": [
    "# Simple tests\n",
    "for _, q in dataset.iterrows():\n",
    "    assert q['answer_text'] == q['context'][q['answer_start']:q['answer_end']]\n",
    "print(\"TEST PASSED: answer-text == context[start:end]\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.2. Data exploration"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99% percentile of context word count: 282\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sentence_lengths = pd.DataFrame(\n",
    "    dataset[['context', 'question']].applymap(str.split).applymap(len).to_numpy(),\n",
    "    columns=['context_word_count', 'question_word_count'],\n",
    ")\n",
    "quantile99 = int(np.quantile(sentence_lengths['context_word_count'], 0.99))\n",
    "\n",
    "ax = sns.histplot(sentence_lengths)\n",
    "ax.axvline(x=quantile99, color='b')\n",
    "print(f\"99% percentile of context word count: {quantile99}\")\n",
    "# Note: after tokenization the numbers may differ but not dramatically"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.3. Tokenization"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, PreTrainedTokenizerFast\n",
    "\n",
    "tokenizer: PreTrainedTokenizerFast = AutoTokenizer.from_pretrained(HF_MODEL_NAME)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test sequence\n",
      "[CLS] test sequence [SEP]\n"
     ]
    }
   ],
   "source": [
    "s = \"Test sequence\"\n",
    "t = tokenizer(\"Test sequence\")\n",
    "print(s)\n",
    "print(tokenizer.decode(t['input_ids']))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/87599 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1acfb2e106e94f67b3619883af8e26d1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Tokenize the context and questions\n",
    "tok = []\n",
    "log_answers_not_found = 0\n",
    "\n",
    "for _, row in tqdm(dataset.iterrows(), total=dataset.shape[0]):\n",
    "    # Standard tokenizer\n",
    "    t = tokenizer(\n",
    "        row['question'],\n",
    "        row['context'],\n",
    "        max_length=512,\n",
    "        truncation='only_second',\n",
    "        padding='max_length',\n",
    "        return_offsets_mapping=True,\n",
    "    )\n",
    "\n",
    "    offset_mapping = np.array(t['offset_mapping'])\n",
    "    token_type_ids = np.array(t['token_type_ids'])\n",
    "\n",
    "    # Get where the answer is located, by looking at tokens that satisfy:\n",
    "    #  - they start after the answer\n",
    "    #  - they end before the answer\n",
    "    #  - they are part of the context\n",
    "    answer_context = (\n",
    "            (offset_mapping[:, 0] >= row['answer_start']) *\n",
    "            (offset_mapping[:, 1] <= row['answer_end']) *\n",
    "            token_type_ids.astype(bool)\n",
    "    )\n",
    "\n",
    "    # Note: for now truncation is not handled\n",
    "    # Debug printing\n",
    "    # print(row['answer_text'])\n",
    "    # print(tokenizer.decode(np.array(t['input_ids'])[answer_context]))\n",
    "    # print(answer_context)\n",
    "\n",
    "    # Get the first and last index of the answer context\n",
    "    answer_tok_idx = np.argwhere(answer_context).ravel()\n",
    "    isp = iep = 0\n",
    "    if answer_tok_idx.size == 0:\n",
    "        log_answers_not_found += 1\n",
    "    else:\n",
    "        isp = answer_tok_idx[0]\n",
    "        iep = answer_tok_idx[-1]\n",
    "        assert isp <= iep\n",
    "\n",
    "    tok.append({\n",
    "        'input_ids': torch.tensor(t['input_ids']),\n",
    "        'token_type_ids': torch.tensor(token_type_ids),\n",
    "        'attention_mask': torch.tensor(t['attention_mask']),\n",
    "        'start_positions': torch.tensor(isp),\n",
    "        'end_positions': torch.tensor(iep),\n",
    "        'offset_mapping': offset_mapping,\n",
    "    })\n",
    "\n",
    "print(f\"Answers not found: {log_answers_not_found}\")\n",
    "# To handle this, we need to do handle larger inputs by slicing or ignore it"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tokenized_dataset = pd.concat((dataset, pd.DataFrame(tok)), axis=1)\n",
    "tokenized_dataset.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Test how the questions+context are tokenized and decoded\n",
    "q = tokenized_dataset.iloc[0]\n",
    "s = q['question'] + q['context']\n",
    "t = q['input_ids']\n",
    "print(s)\n",
    "print()\n",
    "print(tokenizer.decode(t))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.4. Train-Val split"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Get the questions' titles and shuffle them\n",
    "titles = tokenized_dataset['title'].unique()\n",
    "shuffled_titles = pd.Series(titles).sample(frac=1, random_state=RS)\n",
    "\n",
    "# Get the Question Indices grouped by title\n",
    "qi_by_titles = tokenized_dataset.groupby(['title']).indices\n",
    "training_indices = []\n",
    "min_train_len = int(len(tokenized_dataset) * TRAIN_FRACTION)\n",
    "\n",
    "# Add questions until enough are present\n",
    "for title in shuffled_titles:\n",
    "    training_indices += qi_by_titles[title].tolist()\n",
    "    if len(training_indices) >= min_train_len:\n",
    "        break\n",
    "\n",
    "# Create the datasets using the indices\n",
    "ds_train = tokenized_dataset.iloc[training_indices]\n",
    "ds_val = tokenized_dataset.drop(ds_train.index)\n",
    "\n",
    "print(f\"Training samples: {len(ds_train)}\")\n",
    "print(f\"Validation samples: {len(ds_val)}\")\n",
    "print(f\"Actual fraction: {len(ds_train) / len(tokenized_dataset):.4f}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.5. Converting the data for PyTorch"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "\n",
    "class QADataset(Dataset):\n",
    "    def __init__(self, df: pd.DataFrame):\n",
    "        self.df = df\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.df.iloc[idx]\n",
    "        return {\n",
    "            'input_ids': item['input_ids'],\n",
    "            'token_type_ids': item['token_type_ids'],\n",
    "            'attention_mask': item['attention_mask'],\n",
    "            'start_positions': item['start_positions'],\n",
    "            'end_positions': item['end_positions']\n",
    "        }"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_loader = DataLoader(QADataset(ds_train), batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(QADataset(ds_val), batch_size=BATCH_SIZE, shuffle=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. Training the model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.1. Loading the model\n",
    "[docs](https://huggingface.co/docs/transformers/model_doc/bert#transformers.BertForQuestionAnswering)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.1.1. Custom model definition"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from transformers.modeling_outputs import QuestionAnsweringModelOutput\n",
    "from transformers import BertModel\n",
    "from transformers import BertForQuestionAnswering\n",
    "from torchinfo import torchinfo\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class BertForQuestionAnsweringCustom(nn.Module):\n",
    "    \"\"\"\n",
    "    Bert Model for Question Answering Tasks.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, bert_model, num_labels=512, finetune_bert=True):\n",
    "        \"\"\"\n",
    "        @param    bert_model: A BertModel object\n",
    "        @param    num_labels: Number of labels\n",
    "        @param    finetune_bert (bool): Whether to fine-tune the BERT model or not\n",
    "        \"\"\"\n",
    "        super(BertForQuestionAnsweringCustom, self).__init__()\n",
    "\n",
    "        self.bert_model = bert_model\n",
    "        self.num_labels = num_labels\n",
    "        self.qa_head = self.create_head()\n",
    "        self.finetune_bert(finetune_bert)\n",
    "\n",
    "    @classmethod\n",
    "    def from_pretrained(cls, bert_name, num_labels=512, finetune_bert=True):\n",
    "        bert_model = BertModel.from_pretrained(bert_name)\n",
    "        return cls(bert_model, num_labels=num_labels, finetune_bert=finetune_bert)\n",
    "\n",
    "    def finetune_bert(self, finetune):\n",
    "        for param in self.bert_model.parameters():\n",
    "            param.requires_grad = finetune\n",
    "\n",
    "    def create_head(self):\n",
    "        return nn.Linear(self.bert_model.config.hidden_size, self.num_labels * 2)\n",
    "\n",
    "    @classmethod\n",
    "    def loss_fn(cls, start_pred, start_true, end_pred, end_true):\n",
    "        individual_loss_fn = nn.CrossEntropyLoss()\n",
    "        start_loss = individual_loss_fn(start_pred, start_true)\n",
    "        end_loss = individual_loss_fn(end_pred, end_true)\n",
    "        loss = (start_loss + end_loss) / 2\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def forward(self,\n",
    "                input_ids=None,\n",
    "                attention_mask=None,\n",
    "                token_type_ids=None,\n",
    "                position_ids=None,\n",
    "                head_mask=None,\n",
    "                inputs_embeds=None,\n",
    "                start_positions=None,\n",
    "                end_positions=None,\n",
    "                output_attentions=None,\n",
    "                output_hidden_states=None,\n",
    "                return_dict=None\n",
    "                ):\n",
    "        \"\"\"\n",
    "        Feed input to BERT and the classifier to compute logits.\n",
    "        \"\"\"\n",
    "        # Feed input to BERT\n",
    "        outputs = self.bert_model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids,\n",
    "            position_ids=position_ids,\n",
    "            head_mask=head_mask,\n",
    "            inputs_embeds=inputs_embeds,\n",
    "            output_attentions=output_attentions,\n",
    "            output_hidden_states=output_hidden_states,\n",
    "            return_dict=return_dict\n",
    "        )\n",
    "\n",
    "        # Extract the last hidden state of the token `[CLS]` for classification task\n",
    "        last_hidden_state_cls = outputs[0][:, 0, :]\n",
    "\n",
    "        # Feed input to the head to compute logits\n",
    "        logits = self.qa_head(last_hidden_state_cls)\n",
    "        split = logits.split(self.num_labels, dim=1)\n",
    "        start_logits = split[0]\n",
    "        end_logits = split[1]\n",
    "\n",
    "        total_loss = None\n",
    "        if start_positions is not None and end_positions is not None:\n",
    "            total_loss = self.loss_fn(start_logits, start_positions, end_logits, end_positions)\n",
    "\n",
    "        return QuestionAnsweringModelOutput(\n",
    "            loss=total_loss,\n",
    "            start_logits=start_logits,\n",
    "            end_logits=end_logits,\n",
    "            hidden_states=outputs.hidden_states,\n",
    "            attentions=outputs.attentions,\n",
    "        )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "if USE_CUSTOM_MODEL:\n",
    "    model: BertForQuestionAnsweringCustom = BertForQuestionAnsweringCustom.from_pretrained(HF_MODEL_NAME)\n",
    "    print(\"Using custom model\")\n",
    "else:\n",
    "    model: BertForQuestionAnswering = BertForQuestionAnswering.from_pretrained(HF_MODEL_NAME)\n",
    "    print(\"Using Huggingface Question Answering model\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "torchinfo.summary(model)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.2. Metrics"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "\n",
    "def calc_f1(answer_text, answer_text_pred):\n",
    "    f1s = []\n",
    "    for text, pred in zip(answer_text, answer_text_pred):\n",
    "        f1s.append(evaluate.compute_f1(text, pred))\n",
    "    return pd.Series(f1s, name='f1')\n",
    "    # return evaluate.compute_f1(answer_text, answer_text_pred)\n",
    "\n",
    "\n",
    "def calc_em_str(answer_text, answer_text_pred):\n",
    "    # Use string comparison\n",
    "    return (answer_text == answer_text_pred).astype(int).rename('em')\n",
    "\n",
    "\n",
    "def calc_em_tensor(answer_start, answer_end, answer_start_pred, answer_end_pred):\n",
    "    # Use TOKEN index comparison\n",
    "    return torch.logical_and(\n",
    "        answer_start == answer_start_pred,\n",
    "        answer_end == answer_end_pred,\n",
    "    ).float()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.3. Validation / Evaluation function"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def evaluate_model(model, loader: DataLoader, return_frame=False, display_bar=False):\n",
    "    _loader = tqdm(loader) if display_bar else loader\n",
    "\n",
    "    # Store the answers' TOK indices\n",
    "    answer_start_tok= []\n",
    "    answer_end_tok=[]\n",
    "\n",
    "\n",
    "    # Get outputs from the model\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in _loader:\n",
    "            args = dict(\n",
    "                input_ids=batch['input_ids'].to(device),\n",
    "                attention_mask=batch['attention_mask'].to(device),\n",
    "                token_type_ids=batch['token_type_ids'].to(device),\n",
    "            )\n",
    "            outputs = model(**args)\n",
    "\n",
    "            # Get the answers' TOK indices\n",
    "            answer_start_tok += torch.argmax(outputs['start_logits'], dim=1).tolist()\n",
    "            answer_end_tok += torch.argmax(outputs['end_logits'], dim=1).tolist()\n",
    "\n",
    "    # Convert the TOK indices into TEXT using the context\n",
    "    df = loader.dataset.df.reset_index()\n",
    "    answer_text_pred = []\n",
    "    for idx, row in df.iterrows():\n",
    "        om = row['offset_mapping']\n",
    "        tst, ten = answer_start_tok[idx], answer_end_tok[idx]  # Tok start, tok end\n",
    "        cst, cen = om[tst, 0], om[ten, 1]  # Char start, Char end\n",
    "        answer_text_pred.append(row['context'][cst:cen])\n",
    "    answer_text_pred = pd.Series(answer_text_pred)\n",
    "\n",
    "    # Compute the metrics\n",
    "    f1s = calc_f1(df['answer_text'], answer_text_pred)\n",
    "    ems = calc_em_str(df['answer_text'], answer_text_pred)\n",
    "\n",
    "    out = {'f1_mean': sum(f1s)/len(f1s), 'em_mean': sum(ems)/len(ems)}\n",
    "    if return_frame:\n",
    "        out['dataframe'] = pd.concat([df, pd.DataFrame({'answer_text_pred':answer_text_pred, 'f1': f1s, 'em':ems})], axis=1)\n",
    "    return out"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.4 Wandb Integration & Model save-load functions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "Path(MODELS_FOLDER).mkdir(parents=True, exist_ok=True)\n",
    "model_save_name = MODEL_SAVE_NAME if MODEL_SAVE_NAME is not None else HF_MODEL_NAME.split('/')[-1]\n",
    "save_filepath = f\"{MODELS_FOLDER}/{model_save_name}_{datetime.today().strftime('%m%d')}.pt\"\n",
    "\n",
    "def save_model(model, filepath=save_filepath):\n",
    "    torch.save(model.state_dict(), filepath)\n",
    "    # print(f'Model saved in {filepath}')\n",
    "\n",
    "def load_model(model, filepath=save_filepath):\n",
    "    model.load_state_dict(torch.load(filepath))\n",
    "    print(f'Loaded model at {filepath}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%env WANDB_SILENT=True"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import wandb\n",
    "\n",
    "wandb_params = dict(\n",
    "    project=\"NLP-Question-Answering\",\n",
    "    entity=\"frantoman\",\n",
    "    reinit=True,\n",
    "    group=HF_MODEL_NAME,\n",
    "    name=model_save_name,\n",
    "    config=dict(\n",
    "        epochs=EPOCHS,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        learning_rate=LEARNING_RATE,\n",
    "        optimizer='adam',\n",
    "        model_name=HF_MODEL_NAME,\n",
    "    )\n",
    ")\n",
    "\n",
    "run = None\n",
    "if USE_WANDB:\n",
    "    run = wandb.init(**wandb_params)\n",
    "    print(f\"Logging run {run.name} at {run.url}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.5. Training loop"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Initialize stuff\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "model.to(device)\n",
    "opt = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "torch.cuda.empty_cache()\n",
    "model.train()\n",
    "best_f1 = 0  # Used for determining when the model performance over the epochs is degrading\n",
    "\n",
    "# Iterate through the epochs\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    # Epoch's history\n",
    "    ep_loss = []\n",
    "    ep_em = []\n",
    "\n",
    "    train_iter = tqdm(train_loader, desc=f'Epoch {epoch}', leave=True)\n",
    "\n",
    "    # Training\n",
    "    for train_batch in train_iter:\n",
    "        # Extract the model arguments from the batch, and do a forward-pass\n",
    "        opt.zero_grad()\n",
    "        args = dict(\n",
    "            input_ids=train_batch['input_ids'].to(device),\n",
    "            attention_mask=train_batch['attention_mask'].to(device),\n",
    "            start_positions=train_batch['start_positions'].to(device),\n",
    "            end_positions=train_batch['end_positions'].to(device),\n",
    "            token_type_ids=train_batch['token_type_ids'].to(device),\n",
    "        )\n",
    "        outputs = model(**args)\n",
    "\n",
    "        # Get the starting and end token indices\n",
    "        start_pred = torch.argmax(outputs['start_logits'], dim=1)\n",
    "        end_pred = torch.argmax(outputs['end_logits'], dim=1)\n",
    "\n",
    "        # Log the Loss and Exact Matches for the batch\n",
    "        loss = outputs['loss']\n",
    "        em = calc_em_tensor(args['start_positions'], args['end_positions'], start_pred, end_pred)\n",
    "        em_mean = em.mean().item()\n",
    "        ep_loss.append(loss.item())\n",
    "        ep_em.append(em_mean)\n",
    "\n",
    "        # Update the progress bar\n",
    "        train_iter.set_postfix(loss=sum(ep_loss[-50:]) / len(ep_loss[-50:]),\n",
    "                               em=sum(ep_em[-50:]) / len(ep_em[-50:]))\n",
    "\n",
    "        # Backwards-pass\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "    # Validation & Saving\n",
    "    val_out = evaluate_model(model, val_loader)\n",
    "    f1 = val_out['f1_mean']\n",
    "    if f1 > best_f1:\n",
    "        best_f1 = f1\n",
    "        save_model(model)\n",
    "\n",
    "    # End of epoch\n",
    "    train_iter.close()\n",
    "    if USE_WANDB:\n",
    "        run.log(dict(\n",
    "            epoch=epoch,\n",
    "            em=sum(ep_em) / len(ep_em),\n",
    "            loss=sum(ep_loss) / len(ep_loss),\n",
    "            val_em=val_out['em_mean'],\n",
    "            val_f1=val_out['f1_mean'],\n",
    "        ))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.6. Uploading artifacts to Wandb"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Upload the fine-tuned model\n",
    "model_save_artifact = wandb.Artifact('model', type='model')\n",
    "model_save_artifact.add_file(save_filepath)\n",
    "run.log_artifact(model_save_artifact)\n",
    "\n",
    "# Upload some (100) validation outputs of the model\n",
    "load_model(model)\n",
    "out = evaluate_model(model, DataLoader(QADataset(ds_val.iloc[:100])), return_frame=True)\n",
    "df = out['dataframe'][['question', 'context', 'answer_text', 'answer_text_pred', 'f1', 'em']]\n",
    "out_table = wandb.Table(data=df, columns=df.columns)\n",
    "result_artifact = wandb.Artifact('validation_output', type='result')\n",
    "result_artifact.add(out_table, 'validation_output')\n",
    "run.log_artifact(result_artifact)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3. Evaluation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def output_to_file(data: pd.DataFrame):\n",
    "    raw_out = {}\n",
    "    data.apply(lambda row: raw_out.update({row['id']: row['answer_text_pred']}), axis=1)\n",
    "    with open('predictions.txt', 'w+') as fout:\n",
    "        fout.write(json.dumps(raw_out))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# %run evaluate.py \"training_set.json\" \"predictions.txt\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}