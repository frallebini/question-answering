{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Data loading"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.1. Json to Dataframe"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from tqdm.notebook import tqdm as tqdm\n",
    "\n",
    "rs = 42  # Random state\n",
    "# hf_model_name = \"prajjwal1/bert-tiny\"\n",
    "hf_model_name = \"prajjwal1/bert-small\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "data": {
      "text/plain": "                         id                     title  \\\n0  5733be284776f41900661182  University_of_Notre_Dame   \n1  5733be284776f4190066117f  University_of_Notre_Dame   \n2  5733be284776f41900661180  University_of_Notre_Dame   \n3  5733be284776f41900661181  University_of_Notre_Dame   \n4  5733be284776f4190066117e  University_of_Notre_Dame   \n\n                                             context  \\\n0  Architecturally, the school has a Catholic cha...   \n1  Architecturally, the school has a Catholic cha...   \n2  Architecturally, the school has a Catholic cha...   \n3  Architecturally, the school has a Catholic cha...   \n4  Architecturally, the school has a Catholic cha...   \n\n                                            question  \\\n0  To whom did the Virgin Mary allegedly appear i...   \n1  What is in front of the Notre Dame Main Building?   \n2  The Basilica of the Sacred heart at Notre Dame...   \n3                  What is the Grotto at Notre Dame?   \n4  What sits on top of the Main Building at Notre...   \n\n                               answer_text  answer_start  answer_end  \n0               Saint Bernadette Soubirous           515         541  \n1                a copper statue of Christ           188         213  \n2                        the Main Building           279         296  \n3  a Marian place of prayer and reflection           381         420  \n4       a golden statue of the Virgin Mary            92         126  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>title</th>\n      <th>context</th>\n      <th>question</th>\n      <th>answer_text</th>\n      <th>answer_start</th>\n      <th>answer_end</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>5733be284776f41900661182</td>\n      <td>University_of_Notre_Dame</td>\n      <td>Architecturally, the school has a Catholic cha...</td>\n      <td>To whom did the Virgin Mary allegedly appear i...</td>\n      <td>Saint Bernadette Soubirous</td>\n      <td>515</td>\n      <td>541</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>5733be284776f4190066117f</td>\n      <td>University_of_Notre_Dame</td>\n      <td>Architecturally, the school has a Catholic cha...</td>\n      <td>What is in front of the Notre Dame Main Building?</td>\n      <td>a copper statue of Christ</td>\n      <td>188</td>\n      <td>213</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>5733be284776f41900661180</td>\n      <td>University_of_Notre_Dame</td>\n      <td>Architecturally, the school has a Catholic cha...</td>\n      <td>The Basilica of the Sacred heart at Notre Dame...</td>\n      <td>the Main Building</td>\n      <td>279</td>\n      <td>296</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>5733be284776f41900661181</td>\n      <td>University_of_Notre_Dame</td>\n      <td>Architecturally, the school has a Catholic cha...</td>\n      <td>What is the Grotto at Notre Dame?</td>\n      <td>a Marian place of prayer and reflection</td>\n      <td>381</td>\n      <td>420</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5733be284776f4190066117e</td>\n      <td>University_of_Notre_Dame</td>\n      <td>Architecturally, the school has a Catholic cha...</td>\n      <td>What sits on top of the Main Building at Notre...</td>\n      <td>a golden statue of the Virgin Mary</td>\n      <td>92</td>\n      <td>126</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the raw json\n",
    "url = 'training_set.json'\n",
    "with open(url, 'r') as file:\n",
    "    raw = json.load(file)['data']\n",
    "data = []\n",
    "for topic in raw:\n",
    "    for paragraph in topic['paragraphs']:\n",
    "        for question in paragraph['qas']:\n",
    "            assert len(question['answers']) == 1\n",
    "            answer = question['answers'][0]\n",
    "            data.append((\n",
    "                question['id'],\n",
    "                topic['title'],\n",
    "                paragraph['context'],\n",
    "                question['question'],\n",
    "                answer['text'],\n",
    "                answer['answer_start'],\n",
    "                answer['answer_start'] + len(answer['text']),\n",
    "            ))\n",
    "dataset = pd.DataFrame(data,\n",
    "                       columns=('id', 'title', 'context', 'question', 'answer_text', 'answer_start', 'answer_end'))\n",
    "dataset.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 87599 entries, 0 to 87598\n",
      "Data columns (total 7 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   id            87599 non-null  string\n",
      " 1   title         87599 non-null  string\n",
      " 2   context       87599 non-null  string\n",
      " 3   question      87599 non-null  string\n",
      " 4   answer_text   87599 non-null  string\n",
      " 5   answer_start  87599 non-null  Int64 \n",
      " 6   answer_end    87599 non-null  Int64 \n",
      "dtypes: Int64(2), string(5)\n",
      "memory usage: 4.8 MB\n"
     ]
    }
   ],
   "source": [
    "dataset: pd.DataFrame = dataset.apply(pd.to_numeric, errors='ignore').convert_dtypes()\n",
    "# NODE: stripping makes the test in the next cell fail\n",
    "# dataset['context'] = dataset['context'].str.strip()\n",
    "# dataset['question'] = dataset['question'].str.strip()\n",
    "dataset.info()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK: answer-text == context[start:end]\n"
     ]
    }
   ],
   "source": [
    "# Simple tests\n",
    "for _, q in dataset.iterrows():\n",
    "    assert q['answer_text'] == q['context'][q['answer_start']:q['answer_end']]\n",
    "print(\"OK: answer-text == context[start:end]\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.2. Data exploration"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99% percentile of context word count: 282\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sentence_lengths = pd.DataFrame(\n",
    "    dataset[['context', 'question']].applymap(str.split).applymap(len).to_numpy(),\n",
    "    columns=['context_word_count', 'question_word_count'],\n",
    ")\n",
    "quantile99 = int(np.quantile(sentence_lengths['context_word_count'], 0.99))\n",
    "\n",
    "ax = sns.histplot(sentence_lengths)\n",
    "ax.axvline(x=quantile99, color='b')\n",
    "print(f\"99% percentile of context word count: {quantile99}\")\n",
    "# Note: after tokenization the numbers may differ but not dramatically"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.3. Tokenization"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "from transformers import AutoModel\n",
    "import torch\n",
    "from transformers import AutoTokenizer, PreTrainedTokenizerFast\n",
    "\n",
    "tokenizer: PreTrainedTokenizerFast = AutoTokenizer.from_pretrained(hf_model_name)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test sequence\n",
      "[CLS] test sequence [SEP]\n"
     ]
    }
   ],
   "source": [
    "s = \"Test sequence\"\n",
    "t = tokenizer(\"Test sequence\")\n",
    "print(s)\n",
    "print(tokenizer.decode(t['input_ids']))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/87599 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "67b4be911a0c415ba3a332428a027421"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answers not found: 171\n"
     ]
    }
   ],
   "source": [
    "# Tokenize the context and questions\n",
    "tok = []\n",
    "log_answers_not_found = 0\n",
    "\n",
    "for _, row in tqdm(dataset.iterrows(), total=dataset.shape[0]):\n",
    "    # Truncated tokenizer\n",
    "    # t = tokenizer(\n",
    "    #     row['question'],\n",
    "    #     row['context'],\n",
    "    #     max_length=quantile99,\n",
    "    #     truncation=True,\n",
    "    #     padding=\"max_length\",\n",
    "    #     return_offsets_mapping=True,\n",
    "    # )\n",
    "    # Standard tokenizer\n",
    "    t = tokenizer(\n",
    "        row['question'],\n",
    "        row['context'],\n",
    "        max_length=512,\n",
    "        truncation='only_second',\n",
    "        padding='max_length',\n",
    "        return_offsets_mapping=True,\n",
    "    )\n",
    "\n",
    "    offset_mapping = np.array(t['offset_mapping'])\n",
    "    token_type_ids = np.array(t['token_type_ids'])\n",
    "\n",
    "    # Get where the answer is located, by looking at tokens that satisfy:\n",
    "    #  - they start after the answer\n",
    "    #  - they end before the answer\n",
    "    #  - they are part of the context\n",
    "    answer_context = (\n",
    "            (offset_mapping[:, 0] >= row['answer_start']) *\n",
    "            (offset_mapping[:, 1] <= row['answer_end']) *\n",
    "            token_type_ids.astype(bool)\n",
    "    )\n",
    "\n",
    "    # Note: for now truncation is not handled\n",
    "    # Debug printing\n",
    "    # print(row['answer_text'])\n",
    "    # print(tokenizer.decode(np.array(t['input_ids'])[answer_context]))\n",
    "    # print(answer_context)\n",
    "\n",
    "    # Get the first and last index of the answer context\n",
    "    answer_tok_idx = np.argwhere(answer_context).ravel()\n",
    "    isp = iep = 0\n",
    "    if answer_tok_idx.size == 0:\n",
    "        log_answers_not_found += 1\n",
    "    else:\n",
    "        isp = answer_tok_idx[0]\n",
    "        iep = answer_tok_idx[-1]\n",
    "        assert isp <= iep\n",
    "\n",
    "    tok.append({\n",
    "        'input_ids': torch.tensor(t['input_ids']),\n",
    "        'token_type_ids': torch.tensor(token_type_ids),\n",
    "        'attention_mask': torch.tensor(t['attention_mask']),\n",
    "        'start_positions': torch.tensor(isp),\n",
    "        'end_positions': torch.tensor(iep),\n",
    "        'offset_mapping': offset_mapping,\n",
    "    })\n",
    "\n",
    "print(f\"Answers not found: {log_answers_not_found}\")\n",
    "# To handle this, we need to do handle larger inputs by slicing or ignore it"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "data": {
      "text/plain": "                         id                     title  \\\n0  5733be284776f41900661182  University_of_Notre_Dame   \n1  5733be284776f4190066117f  University_of_Notre_Dame   \n2  5733be284776f41900661180  University_of_Notre_Dame   \n3  5733be284776f41900661181  University_of_Notre_Dame   \n4  5733be284776f4190066117e  University_of_Notre_Dame   \n\n                                             context  \\\n0  Architecturally, the school has a Catholic cha...   \n1  Architecturally, the school has a Catholic cha...   \n2  Architecturally, the school has a Catholic cha...   \n3  Architecturally, the school has a Catholic cha...   \n4  Architecturally, the school has a Catholic cha...   \n\n                                            question  \\\n0  To whom did the Virgin Mary allegedly appear i...   \n1  What is in front of the Notre Dame Main Building?   \n2  The Basilica of the Sacred heart at Notre Dame...   \n3                  What is the Grotto at Notre Dame?   \n4  What sits on top of the Main Building at Notre...   \n\n                               answer_text  answer_start  answer_end  \\\n0               Saint Bernadette Soubirous           515         541   \n1                a copper statue of Christ           188         213   \n2                        the Main Building           279         296   \n3  a Marian place of prayer and reflection           381         420   \n4       a golden statue of the Virgin Mary            92         126   \n\n                                           input_ids  \\\n0  [tensor(101), tensor(2000), tensor(3183), tens...   \n1  [tensor(101), tensor(2054), tensor(2003), tens...   \n2  [tensor(101), tensor(1996), tensor(13546), ten...   \n3  [tensor(101), tensor(2054), tensor(2003), tens...   \n4  [tensor(101), tensor(2054), tensor(7719), tens...   \n\n                                      token_type_ids  \\\n0  [tensor(0, dtype=torch.int32), tensor(0, dtype...   \n1  [tensor(0, dtype=torch.int32), tensor(0, dtype...   \n2  [tensor(0, dtype=torch.int32), tensor(0, dtype...   \n3  [tensor(0, dtype=torch.int32), tensor(0, dtype...   \n4  [tensor(0, dtype=torch.int32), tensor(0, dtype...   \n\n                                      attention_mask start_positions  \\\n0  [tensor(1), tensor(1), tensor(1), tensor(1), t...     tensor(130)   \n1  [tensor(1), tensor(1), tensor(1), tensor(1), t...      tensor(52)   \n2  [tensor(1), tensor(1), tensor(1), tensor(1), t...      tensor(81)   \n3  [tensor(1), tensor(1), tensor(1), tensor(1), t...      tensor(95)   \n4  [tensor(1), tensor(1), tensor(1), tensor(1), t...      tensor(33)   \n\n  end_positions                                     offset_mapping  \n0   tensor(137)  [[0, 0], [0, 2], [3, 7], [8, 11], [12, 15], [1...  \n1    tensor(56)  [[0, 0], [0, 4], [5, 7], [8, 10], [11, 16], [1...  \n2    tensor(83)  [[0, 0], [0, 3], [4, 12], [13, 15], [16, 19], ...  \n3   tensor(101)  [[0, 0], [0, 4], [5, 7], [8, 11], [12, 14], [1...  \n4    tensor(39)  [[0, 0], [0, 4], [5, 9], [10, 12], [13, 16], [...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>title</th>\n      <th>context</th>\n      <th>question</th>\n      <th>answer_text</th>\n      <th>answer_start</th>\n      <th>answer_end</th>\n      <th>input_ids</th>\n      <th>token_type_ids</th>\n      <th>attention_mask</th>\n      <th>start_positions</th>\n      <th>end_positions</th>\n      <th>offset_mapping</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>5733be284776f41900661182</td>\n      <td>University_of_Notre_Dame</td>\n      <td>Architecturally, the school has a Catholic cha...</td>\n      <td>To whom did the Virgin Mary allegedly appear i...</td>\n      <td>Saint Bernadette Soubirous</td>\n      <td>515</td>\n      <td>541</td>\n      <td>[tensor(101), tensor(2000), tensor(3183), tens...</td>\n      <td>[tensor(0, dtype=torch.int32), tensor(0, dtype...</td>\n      <td>[tensor(1), tensor(1), tensor(1), tensor(1), t...</td>\n      <td>tensor(130)</td>\n      <td>tensor(137)</td>\n      <td>[[0, 0], [0, 2], [3, 7], [8, 11], [12, 15], [1...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>5733be284776f4190066117f</td>\n      <td>University_of_Notre_Dame</td>\n      <td>Architecturally, the school has a Catholic cha...</td>\n      <td>What is in front of the Notre Dame Main Building?</td>\n      <td>a copper statue of Christ</td>\n      <td>188</td>\n      <td>213</td>\n      <td>[tensor(101), tensor(2054), tensor(2003), tens...</td>\n      <td>[tensor(0, dtype=torch.int32), tensor(0, dtype...</td>\n      <td>[tensor(1), tensor(1), tensor(1), tensor(1), t...</td>\n      <td>tensor(52)</td>\n      <td>tensor(56)</td>\n      <td>[[0, 0], [0, 4], [5, 7], [8, 10], [11, 16], [1...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>5733be284776f41900661180</td>\n      <td>University_of_Notre_Dame</td>\n      <td>Architecturally, the school has a Catholic cha...</td>\n      <td>The Basilica of the Sacred heart at Notre Dame...</td>\n      <td>the Main Building</td>\n      <td>279</td>\n      <td>296</td>\n      <td>[tensor(101), tensor(1996), tensor(13546), ten...</td>\n      <td>[tensor(0, dtype=torch.int32), tensor(0, dtype...</td>\n      <td>[tensor(1), tensor(1), tensor(1), tensor(1), t...</td>\n      <td>tensor(81)</td>\n      <td>tensor(83)</td>\n      <td>[[0, 0], [0, 3], [4, 12], [13, 15], [16, 19], ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>5733be284776f41900661181</td>\n      <td>University_of_Notre_Dame</td>\n      <td>Architecturally, the school has a Catholic cha...</td>\n      <td>What is the Grotto at Notre Dame?</td>\n      <td>a Marian place of prayer and reflection</td>\n      <td>381</td>\n      <td>420</td>\n      <td>[tensor(101), tensor(2054), tensor(2003), tens...</td>\n      <td>[tensor(0, dtype=torch.int32), tensor(0, dtype...</td>\n      <td>[tensor(1), tensor(1), tensor(1), tensor(1), t...</td>\n      <td>tensor(95)</td>\n      <td>tensor(101)</td>\n      <td>[[0, 0], [0, 4], [5, 7], [8, 11], [12, 14], [1...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5733be284776f4190066117e</td>\n      <td>University_of_Notre_Dame</td>\n      <td>Architecturally, the school has a Catholic cha...</td>\n      <td>What sits on top of the Main Building at Notre...</td>\n      <td>a golden statue of the Virgin Mary</td>\n      <td>92</td>\n      <td>126</td>\n      <td>[tensor(101), tensor(2054), tensor(7719), tens...</td>\n      <td>[tensor(0, dtype=torch.int32), tensor(0, dtype...</td>\n      <td>[tensor(1), tensor(1), tensor(1), tensor(1), t...</td>\n      <td>tensor(33)</td>\n      <td>tensor(39)</td>\n      <td>[[0, 0], [0, 4], [5, 9], [10, 12], [13, 16], [...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset = pd.concat((dataset, pd.DataFrame(tok)), axis=1)\n",
    "tokenized_dataset.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France?Architecturally, the school has a Catholic character. Atop the Main Building's gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive (and in a direct line that connects through 3 statues and the Gold Dome), is a simple, modern stone statue of Mary.\n",
      "\n",
      "[CLS] to whom did the virgin mary allegedly appear in 1858 in lourdes france? [SEP] architecturally, the school has a catholic character. atop the main building's gold dome is a golden statue of the virgin mary. immediately in front of the main building and facing it, is a copper statue of christ with arms upraised with the legend \" venite ad me omnes \". next to the main building is the basilica of the sacred heart. immediately behind the basilica is the grotto, a marian place of prayer and reflection. it is a replica of the grotto at lourdes, france where the virgin mary reputedly appeared to saint bernadette soubirous in 1858. at the end of the main drive ( and in a direct line that connects through 3 statues and the gold dome ), is a simple, modern stone statue of mary. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n"
     ]
    }
   ],
   "source": [
    "# Test how the questions+context are tokenized and decoded\n",
    "q = tokenized_dataset.iloc[0]\n",
    "s = q['question'] + q['context']\n",
    "t = q['input_ids']\n",
    "print(s)\n",
    "print()\n",
    "print(tokenizer.decode(t))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.4. Train-Val split"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 65699\n",
      "Validation samples: 21900\n",
      "Actual fraction: 0.75\n"
     ]
    }
   ],
   "source": [
    "train_fraction = 0.75\n",
    "ds_train = tokenized_dataset.sample(frac=train_fraction, random_state=rs)\n",
    "ds_val = tokenized_dataset.drop(ds_train.index)\n",
    "\n",
    "print(f\"Training samples: {len(ds_train)}\")\n",
    "print(f\"Validation samples: {len(ds_val)}\")\n",
    "print(f\"Actual fraction: {len(ds_train) / len(tokenized_dataset):.2f}\")\n",
    "\n",
    "del tokenized_dataset\n",
    "del dataset\n",
    "del tok"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "data": {
      "text/plain": "9983     512\n43267    512\n81021    512\n49374    512\n53414    512\n        ... \n13133    512\n53830    512\n32956    512\n47062    512\n62678    512\nName: input_ids, Length: 65699, dtype: int64"
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_train['input_ids'].apply(len)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. Training the model\n",
    "### 2.1. Loading the model\n",
    "[docs](https://huggingface.co/docs/transformers/model_doc/bert#transformers.BertForQuestionAnswering)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "data": {
      "text/plain": "Downloading:   0%|          | 0.00/111M [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4e3ba64d57a04ca496ff3bb9e9983d1a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at prajjwal1/bert-small were not used when initializing BertForQuestionAnswering: ['cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at prajjwal1/bert-small and are newly initialized: ['qa_outputs.weight', 'qa_outputs.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertForQuestionAnswering\n",
    "from torchinfo import torchinfo\n",
    "\n",
    "model: BertForQuestionAnswering = BertForQuestionAnswering.from_pretrained(hf_model_name)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "data": {
      "text/plain": "================================================================================\nLayer (type:depth-idx)                                  Param #\n================================================================================\nBertForQuestionAnswering                                --\n├─BertModel: 1-1                                        --\n│    └─BertEmbeddings: 2-1                              --\n│    │    └─Embedding: 3-1                              15,627,264\n│    │    └─Embedding: 3-2                              262,144\n│    │    └─Embedding: 3-3                              1,024\n│    │    └─LayerNorm: 3-4                              1,024\n│    │    └─Dropout: 3-5                                --\n│    └─BertEncoder: 2-2                                 --\n│    │    └─ModuleList: 3-6                             12,609,536\n├─Linear: 1-2                                           1,026\n================================================================================\nTotal params: 28,502,018\nTrainable params: 28,502,018\nNon-trainable params: 0\n================================================================================"
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torchinfo.summary(model)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.2. Training loop"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset, Dataset\n",
    "\n",
    "\n",
    "class QADataset(Dataset):\n",
    "    def __init__(self, df: pd.DataFrame):\n",
    "        self.df = df\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.df.iloc[idx]\n",
    "        return {\n",
    "            'input_ids': item['input_ids'],\n",
    "            'token_type_ids': item['token_type_ids'],\n",
    "            'attention_mask': item['attention_mask'],\n",
    "            'start_positions': item['start_positions'],\n",
    "            'end_positions': item['end_positions']\n",
    "        }\n",
    "\n",
    "\n",
    "batch_size = 16\n",
    "epochs = 5\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "model.to(device)\n",
    "train_loader = DataLoader(QADataset(ds_train), batch_size=batch_size, shuffle=True)\n",
    "opt = torch.optim.Adam(model.parameters(), lr=5e-5)\n",
    "# opt = torch.optim.AdamW(model.parameters(), lr=5e-5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [],
   "source": [
    "def n_correct(pred: torch.Tensor, true: torch.Tensor) -> float:\n",
    "    assert len(pred) == len(true)\n",
    "    return (pred == true).sum().item()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "data": {
      "text/plain": "Epoch 1:   0%|          | 0/4107 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8e8b0d419b5642baad6738eec4243974"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Epoch 2:   0%|          | 0/4107 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6c5919c8a4f84745a35f57e3175bb7af"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Epoch 3:   0%|          | 0/4107 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2fbf30ce53d740459202f30733d059a9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Epoch 4:   0%|          | 0/4107 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "213c1fc8ac834d709a2e394f8873d188"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Epoch 5:   0%|          | 0/4107 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "28ce4db815154dde82ccec2912474018"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "model.train()\n",
    "\n",
    "history_loss = []\n",
    "history_acc = []\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    # Epoch history\n",
    "    ep_loss = []\n",
    "    ep_acc = []\n",
    "\n",
    "    train_iter = tqdm(train_loader, desc=f'Epoch {epoch}', leave=True)\n",
    "\n",
    "    for train_batch in train_iter:\n",
    "        input_ids = train_batch['input_ids'].to(device)\n",
    "        attention_mask = train_batch['attention_mask'].to(device)\n",
    "        start_true = train_batch['start_positions'].to(device)\n",
    "        end_true = train_batch['end_positions'].to(device)\n",
    "        token_type_ids = train_batch['token_type_ids'].to(device)\n",
    "\n",
    "        opt.zero_grad()\n",
    "        outputs = model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids,\n",
    "            start_positions=start_true,\n",
    "            end_positions=end_true,\n",
    "        )\n",
    "\n",
    "        start_pred = torch.argmax(outputs['start_logits'], dim=1)\n",
    "        end_pred = torch.argmax(outputs['end_logits'], dim=1)\n",
    "        loss = outputs['loss']\n",
    "\n",
    "        n_samples = len(start_true)\n",
    "        n_correct_start = n_correct(start_pred, start_true)\n",
    "        n_correct_end = n_correct(end_pred, end_true)\n",
    "        n_correct_avg = (n_correct_start + n_correct_end) / 2\n",
    "\n",
    "        ep_loss.append(loss.item())\n",
    "        ep_acc.append(n_correct_avg / n_samples)\n",
    "\n",
    "        train_iter.set_postfix(loss=sum(ep_loss[-50:]) / len(ep_loss[-50:]),\n",
    "                               acc=sum(ep_acc[-50:]) / len(ep_acc[-50:]))\n",
    "\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "    # End of epoch\n",
    "    train_iter.close()\n",
    "    history_loss.append(sum(ep_loss) / len(ep_loss))\n",
    "    history_acc.append(sum(ep_acc) / len(ep_acc))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved in ./models/smallbert_0128.pt\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "models_folder = './models'\n",
    "model_name = 'smallbert'\n",
    "\n",
    "Path(models_folder).mkdir(parents=True, exist_ok=True)\n",
    "filepath = f\"{models_folder}/{model_name}_{datetime.today().strftime('%m%d')}.pt\"\n",
    "torch.save(model.state_dict(), filepath)\n",
    "print(f'Model saved in {filepath}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3. Evaluation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model at ./models/smallbert_0128.pt\n"
     ]
    }
   ],
   "source": [
    "filepath = models_folder + '/' + model_name + \"_0128.pt\"\n",
    "model.load_state_dict(torch.load(filepath))\n",
    "print(f'Loaded model at {filepath}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/21900 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7a37947eb003458abf0b08a12f6b24da"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "indexes = []\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    ds = ds_val  # Change to ds_val for validation\n",
    "    for _, row in tqdm(ds.iterrows(), total=len(ds)):\n",
    "        # torch.cuda.empty_cache()\n",
    "        args = dict(\n",
    "            input_ids=row['input_ids'][None].to(device),\n",
    "            attention_mask=row['attention_mask'][None].to(device),\n",
    "            start_positions=row['start_positions'][None].to(device),\n",
    "            end_positions=row['end_positions'][None].to(device),\n",
    "            token_type_ids=row['token_type_ids'][None].to(device),\n",
    "        )\n",
    "        outputs = model(**args)\n",
    "\n",
    "        start_pred = torch.argmax(outputs['start_logits'], dim=1)\n",
    "        end_pred = torch.argmax(outputs['end_logits'], dim=1)\n",
    "        idx_start_pred = row['offset_mapping'][start_pred, 0]\n",
    "        idx_end_pred = row['offset_mapping'][end_pred, 1]\n",
    "        indexes.append({\n",
    "            'answer_start_pred': idx_start_pred.item(),\n",
    "            'answer_end_pred': idx_end_pred.item(),\n",
    "        })\n",
    "\n",
    "res = pd.concat((ds.reset_index(), pd.DataFrame(indexes)), axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "data": {
      "text/plain": "   index                        id                     title  \\\n0      2  5733be284776f41900661180  University_of_Notre_Dame   \n1      5  5733bf84d058e614000b61be  University_of_Notre_Dame   \n2     14  5733bed24776f4190066118c  University_of_Notre_Dame   \n3     15  5733a6424776f41900660f51  University_of_Notre_Dame   \n4     16  5733a6424776f41900660f4e  University_of_Notre_Dame   \n\n                                             context  \\\n0  Architecturally, the school has a Catholic cha...   \n1  As at most other universities, Notre Dame's st...   \n2  The university is the major seat of the Congre...   \n3  The College of Engineering was established in ...   \n4  The College of Engineering was established in ...   \n\n                                            question  \\\n0  The Basilica of the Sacred heart at Notre Dame...   \n1  When did the Scholastic Magazine of Notre dame...   \n2         Which prize did Frederick Buechner create?   \n3  How many BS level degrees are offered in the C...   \n4  In what year was the College of Engineering at...   \n\n                    answer_text  answer_start  answer_end  \\\n0             the Main Building           279         296   \n1                September 1876           248         262   \n2  Buechner Prize for Preaching           675         703   \n3                         eight           487         492   \n4                          1920            46          50   \n\n                                           input_ids  \\\n0  [tensor(101), tensor(1996), tensor(13546), ten...   \n1  [tensor(101), tensor(2043), tensor(2106), tens...   \n2  [tensor(101), tensor(2029), tensor(3396), tens...   \n3  [tensor(101), tensor(2129), tensor(2116), tens...   \n4  [tensor(101), tensor(1999), tensor(2054), tens...   \n\n                                      token_type_ids  \\\n0  [tensor(0, dtype=torch.int32), tensor(0, dtype...   \n1  [tensor(0, dtype=torch.int32), tensor(0, dtype...   \n2  [tensor(0, dtype=torch.int32), tensor(0, dtype...   \n3  [tensor(0, dtype=torch.int32), tensor(0, dtype...   \n4  [tensor(0, dtype=torch.int32), tensor(0, dtype...   \n\n                                      attention_mask start_positions  \\\n0  [tensor(1), tensor(1), tensor(1), tensor(1), t...      tensor(81)   \n1  [tensor(1), tensor(1), tensor(1), tensor(1), t...      tensor(63)   \n2  [tensor(1), tensor(1), tensor(1), tensor(1), t...     tensor(149)   \n3  [tensor(1), tensor(1), tensor(1), tensor(1), t...     tensor(107)   \n4  [tensor(1), tensor(1), tensor(1), tensor(1), t...      tensor(22)   \n\n  end_positions                                     offset_mapping  \\\n0    tensor(83)  [[0, 0], [0, 3], [4, 12], [13, 15], [16, 19], ...   \n1    tensor(64)  [[0, 0], [0, 4], [5, 8], [9, 12], [13, 23], [2...   \n2   tensor(154)  [[0, 0], [0, 5], [6, 11], [12, 15], [16, 25], ...   \n3   tensor(107)  [[0, 0], [0, 3], [4, 8], [9, 11], [12, 17], [1...   \n4    tensor(22)  [[0, 0], [0, 2], [3, 7], [8, 12], [13, 16], [1...   \n\n   answer_start_pred  answer_end_pred  \n0                369              379  \n1                248              262  \n2                694              703  \n3                487              492  \n4                 46               50  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>index</th>\n      <th>id</th>\n      <th>title</th>\n      <th>context</th>\n      <th>question</th>\n      <th>answer_text</th>\n      <th>answer_start</th>\n      <th>answer_end</th>\n      <th>input_ids</th>\n      <th>token_type_ids</th>\n      <th>attention_mask</th>\n      <th>start_positions</th>\n      <th>end_positions</th>\n      <th>offset_mapping</th>\n      <th>answer_start_pred</th>\n      <th>answer_end_pred</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2</td>\n      <td>5733be284776f41900661180</td>\n      <td>University_of_Notre_Dame</td>\n      <td>Architecturally, the school has a Catholic cha...</td>\n      <td>The Basilica of the Sacred heart at Notre Dame...</td>\n      <td>the Main Building</td>\n      <td>279</td>\n      <td>296</td>\n      <td>[tensor(101), tensor(1996), tensor(13546), ten...</td>\n      <td>[tensor(0, dtype=torch.int32), tensor(0, dtype...</td>\n      <td>[tensor(1), tensor(1), tensor(1), tensor(1), t...</td>\n      <td>tensor(81)</td>\n      <td>tensor(83)</td>\n      <td>[[0, 0], [0, 3], [4, 12], [13, 15], [16, 19], ...</td>\n      <td>369</td>\n      <td>379</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>5</td>\n      <td>5733bf84d058e614000b61be</td>\n      <td>University_of_Notre_Dame</td>\n      <td>As at most other universities, Notre Dame's st...</td>\n      <td>When did the Scholastic Magazine of Notre dame...</td>\n      <td>September 1876</td>\n      <td>248</td>\n      <td>262</td>\n      <td>[tensor(101), tensor(2043), tensor(2106), tens...</td>\n      <td>[tensor(0, dtype=torch.int32), tensor(0, dtype...</td>\n      <td>[tensor(1), tensor(1), tensor(1), tensor(1), t...</td>\n      <td>tensor(63)</td>\n      <td>tensor(64)</td>\n      <td>[[0, 0], [0, 4], [5, 8], [9, 12], [13, 23], [2...</td>\n      <td>248</td>\n      <td>262</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>14</td>\n      <td>5733bed24776f4190066118c</td>\n      <td>University_of_Notre_Dame</td>\n      <td>The university is the major seat of the Congre...</td>\n      <td>Which prize did Frederick Buechner create?</td>\n      <td>Buechner Prize for Preaching</td>\n      <td>675</td>\n      <td>703</td>\n      <td>[tensor(101), tensor(2029), tensor(3396), tens...</td>\n      <td>[tensor(0, dtype=torch.int32), tensor(0, dtype...</td>\n      <td>[tensor(1), tensor(1), tensor(1), tensor(1), t...</td>\n      <td>tensor(149)</td>\n      <td>tensor(154)</td>\n      <td>[[0, 0], [0, 5], [6, 11], [12, 15], [16, 25], ...</td>\n      <td>694</td>\n      <td>703</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>15</td>\n      <td>5733a6424776f41900660f51</td>\n      <td>University_of_Notre_Dame</td>\n      <td>The College of Engineering was established in ...</td>\n      <td>How many BS level degrees are offered in the C...</td>\n      <td>eight</td>\n      <td>487</td>\n      <td>492</td>\n      <td>[tensor(101), tensor(2129), tensor(2116), tens...</td>\n      <td>[tensor(0, dtype=torch.int32), tensor(0, dtype...</td>\n      <td>[tensor(1), tensor(1), tensor(1), tensor(1), t...</td>\n      <td>tensor(107)</td>\n      <td>tensor(107)</td>\n      <td>[[0, 0], [0, 3], [4, 8], [9, 11], [12, 17], [1...</td>\n      <td>487</td>\n      <td>492</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>16</td>\n      <td>5733a6424776f41900660f4e</td>\n      <td>University_of_Notre_Dame</td>\n      <td>The College of Engineering was established in ...</td>\n      <td>In what year was the College of Engineering at...</td>\n      <td>1920</td>\n      <td>46</td>\n      <td>50</td>\n      <td>[tensor(101), tensor(1999), tensor(2054), tens...</td>\n      <td>[tensor(0, dtype=torch.int32), tensor(0, dtype...</td>\n      <td>[tensor(1), tensor(1), tensor(1), tensor(1), t...</td>\n      <td>tensor(22)</td>\n      <td>tensor(22)</td>\n      <td>[[0, 0], [0, 2], [3, 7], [8, 12], [13, 16], [1...</td>\n      <td>46</td>\n      <td>50</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.6250\n"
     ]
    }
   ],
   "source": [
    "accuracy_start = np.sum(res['answer_start_pred'] == res['answer_start']) / len(res)\n",
    "accuracy_end = np.sum(res['answer_end_pred'] == res['answer_end']) / len(res)\n",
    "accuracy_glob = (accuracy_start + accuracy_end) / 2\n",
    "print(f\"Accuracy {accuracy_glob:.4f}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [],
   "source": [
    "res['answer_text_pred'] = res.apply(lambda row: row['context'][row['answer_start_pred']:row['answer_end_pred']], axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [
    {
     "data": {
      "text/plain": "                                             question  \\\n0   The Basilica of the Sacred heart at Notre Dame...   \n1   When did the Scholastic Magazine of Notre dame...   \n2          Which prize did Frederick Buechner create?   \n3   How many BS level degrees are offered in the C...   \n4   In what year was the College of Engineering at...   \n..                                                ...   \n95  What singer did Beyonce record a song with for...   \n96     Where did Destiny's Child get their name from?   \n97   What was Destiny's Child's first major song hit?   \n98   What mental health issue did Beyonce go through?   \n99  What event occured after she was publicly crit...   \n\n                                              context  \\\n0   Architecturally, the school has a Catholic cha...   \n1   As at most other universities, Notre Dame's st...   \n2   The university is the major seat of the Congre...   \n3   The College of Engineering was established in ...   \n4   The College of Engineering was established in ...   \n..                                                ...   \n95  The group changed their name to Destiny's Chil...   \n96  The group changed their name to Destiny's Chil...   \n97  The group changed their name to Destiny's Chil...   \n98  LeToya Luckett and Roberson became unhappy wit...   \n99  LeToya Luckett and Roberson became unhappy wit...   \n\n                     answer_text answer_text_pred  \n0              the Main Building       the Grotto  \n1                 September 1876   September 1876  \n2   Buechner Prize for Preaching        Preaching  \n3                          eight            eight  \n4                           1920             1920  \n..                           ...              ...  \n95                   Marc Nelson      Marc Nelson  \n96               Book of Isaiah.   Book of Isaiah  \n97                    No, No, No      No, No, No\"  \n98                    depression       depression  \n99            boyfriend left her       depression  \n\n[100 rows x 4 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>question</th>\n      <th>context</th>\n      <th>answer_text</th>\n      <th>answer_text_pred</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>The Basilica of the Sacred heart at Notre Dame...</td>\n      <td>Architecturally, the school has a Catholic cha...</td>\n      <td>the Main Building</td>\n      <td>the Grotto</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>When did the Scholastic Magazine of Notre dame...</td>\n      <td>As at most other universities, Notre Dame's st...</td>\n      <td>September 1876</td>\n      <td>September 1876</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Which prize did Frederick Buechner create?</td>\n      <td>The university is the major seat of the Congre...</td>\n      <td>Buechner Prize for Preaching</td>\n      <td>Preaching</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>How many BS level degrees are offered in the C...</td>\n      <td>The College of Engineering was established in ...</td>\n      <td>eight</td>\n      <td>eight</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>In what year was the College of Engineering at...</td>\n      <td>The College of Engineering was established in ...</td>\n      <td>1920</td>\n      <td>1920</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>95</th>\n      <td>What singer did Beyonce record a song with for...</td>\n      <td>The group changed their name to Destiny's Chil...</td>\n      <td>Marc Nelson</td>\n      <td>Marc Nelson</td>\n    </tr>\n    <tr>\n      <th>96</th>\n      <td>Where did Destiny's Child get their name from?</td>\n      <td>The group changed their name to Destiny's Chil...</td>\n      <td>Book of Isaiah.</td>\n      <td>Book of Isaiah</td>\n    </tr>\n    <tr>\n      <th>97</th>\n      <td>What was Destiny's Child's first major song hit?</td>\n      <td>The group changed their name to Destiny's Chil...</td>\n      <td>No, No, No</td>\n      <td>No, No, No\"</td>\n    </tr>\n    <tr>\n      <th>98</th>\n      <td>What mental health issue did Beyonce go through?</td>\n      <td>LeToya Luckett and Roberson became unhappy wit...</td>\n      <td>depression</td>\n      <td>depression</td>\n    </tr>\n    <tr>\n      <th>99</th>\n      <td>What event occured after she was publicly crit...</td>\n      <td>LeToya Luckett and Roberson became unhappy wit...</td>\n      <td>boyfriend left her</td>\n      <td>depression</td>\n    </tr>\n  </tbody>\n</table>\n<p>100 rows × 4 columns</p>\n</div>"
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[['question', 'context', 'answer_text', 'answer_text_pred']][:100]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}