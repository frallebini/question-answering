{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "% load_ext autoreload\n",
    "% autoreload 2\n",
    "\n",
    "import torch\n",
    "from config import conf\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Adam\n",
    "from transformers import DistilBertTokenizerFast, DistilBertForQuestionAnswering\n",
    "from tqdm import tqdm\n",
    "from dataset import SquadDataset\n",
    "from torch.nn import Module\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "torch.cuda.is_available()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "TRAIN_MODEL = True\n",
    "SAVE_MODEL = True\n",
    "MODELS_FOLDER = \"./models\"\n",
    "MODEL_LOAD_NAME = \"model_0125.pt\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')\n",
    "dataset = SquadDataset.from_json(conf['DATASET_FILE'], tokenizer)\n",
    "train_dataset, val_dataset = dataset.train_val_split(conf['TRAIN_RATIO'])\n",
    "\n",
    "model: Module = DistilBertForQuestionAnswering.from_pretrained('distilbert-base-uncased')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def compute_accuracy(pred: torch.Tensor, true: torch.Tensor) -> float:\n",
    "    assert len(pred) == len(true)\n",
    "    #TODO: check the sum\n",
    "    return ((start_pred == start_true).sum() / len(start_pred)).item()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "model.to(device)\n",
    "\n",
    "if TRAIN_MODEL:\n",
    "    opt = Adam(model.parameters(), lr=5e-5)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=conf['BATCH_SIZE'], shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=conf['BATCH_SIZE'])\n",
    "\n",
    "    for epoch in range(conf['N_EPOCHS']):\n",
    "        # ================================ TRAINING ================================\n",
    "        model.train()\n",
    "\n",
    "        train_losses = []\n",
    "        train_accs = []\n",
    "\n",
    "        train_iter = tqdm(train_loader)\n",
    "        train_iter.set_description(f'Epoch {epoch}')\n",
    "\n",
    "        for train_batch in train_iter:\n",
    "            input_ids = train_batch['input_ids'].to(device)\n",
    "            attention_mask = train_batch['attention_mask'].to(device)\n",
    "            start_true = train_batch['start_positions'].to(device)\n",
    "            end_true = train_batch['end_positions'].to(device)\n",
    "\n",
    "            outputs = model(input_ids,\n",
    "                            attention_mask=attention_mask,\n",
    "                            start_positions=start_true,\n",
    "                            end_positions=end_true)\n",
    "            start_pred = torch.argmax(outputs['start_logits'], dim=1)\n",
    "            end_pred = torch.argmax(outputs['end_logits'], dim=1)\n",
    "\n",
    "            loss = outputs['loss']\n",
    "            start_acc = compute_accuracy(start_pred, start_true)\n",
    "            end_acc = compute_accuracy(end_pred, end_true)\n",
    "            train_iter.set_postfix(loss=loss.item(),\n",
    "                                   acc=(start_acc + end_acc) / 2)\n",
    "\n",
    "            train_losses.append(loss.item())\n",
    "            train_accs.append(start_acc)\n",
    "            train_accs.append(end_acc)\n",
    "\n",
    "            loss.backward()\n",
    "\n",
    "            opt.step()\n",
    "            opt.zero_grad()\n",
    "\n",
    "        # =============================== VALIDATION ===============================\n",
    "        model.eval()\n",
    "\n",
    "        val_losses = [0]\n",
    "        val_accs = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for val_batch in val_loader:\n",
    "                input_ids = val_batch['input_ids'].to(device)\n",
    "                attention_mask = val_batch['attention_mask'].to(device)\n",
    "                start_true = val_batch['start_positions'].to(device)\n",
    "                end_true = val_batch['end_positions'].to(device)\n",
    "\n",
    "                outputs = model(input_ids, attention_mask=attention_mask)\n",
    "                start_pred = torch.argmax(outputs['start_logits'], dim=1)\n",
    "                end_pred = torch.argmax(outputs['end_logits'], dim=1)\n",
    "\n",
    "                # val_losses.append(outputs['loss']) #TODO: check missing key\n",
    "                val_accs.append(compute_accuracy(start_pred, start_true))\n",
    "                val_accs.append(compute_accuracy(end_pred, end_true))\n",
    "\n",
    "        train_iter.set_postfix(loss=sum(train_losses) / len(train_losses),\n",
    "                               acc=sum(train_accs) / len(train_accs),\n",
    "                               val_loss=sum(val_losses) / len(val_losses),\n",
    "                               val_acc=sum(val_accs) / len(val_accs))\n",
    "    # SAVING\n",
    "    if SAVE_MODEL:\n",
    "        Path(MODELS_FOLDER).mkdir(parents=True, exist_ok=True)\n",
    "        filepath = f\"{MODELS_FOLDER}/model_{datetime.today().strftime('%m%d')}.pt\"\n",
    "        torch.save(model.state_dict(), filepath)\n",
    "        print(f\"Model saved in {filepath}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# =============================== TESTING ===============================\n",
    "test_dataset = val_dataset  # we don't actually have the testing ds yet\n",
    "test_loader = DataLoader(test_dataset, batch_size=conf['BATCH_SIZE'])\n",
    "\n",
    "if not TRAIN_MODEL:\n",
    "    filepath = MODELS_FOLDER + '/' + MODEL_LOAD_NAME\n",
    "    model.load_state_dict(torch.load(filepath))\n",
    "    print(f\"Loaded model at {filepath}\")\n",
    "\n",
    "model.eval()\n",
    "test_losses = []\n",
    "test_accs = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for test_batch in test_loader:\n",
    "        input_ids = test_batch['input_ids'].to(device)\n",
    "        attention_mask = test_batch['attention_mask'].to(device)\n",
    "        start_true = test_batch['start_positions'].to(device)\n",
    "        end_true = test_batch['end_positions'].to(device)\n",
    "\n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "        start_pred = torch.argmax(outputs['start_logits'], dim=1)\n",
    "        end_pred = torch.argmax(outputs['end_logits'], dim=1)\n",
    "\n",
    "        # test_losses.append(outputs['loss']) #TODO: check missing key (same as validation)\n",
    "        test_accs.append(compute_accuracy(start_pred, start_true))\n",
    "        test_accs.append(compute_accuracy(end_pred, end_true))\n",
    "\n",
    "print(f\"Average test accuracy: {sum(test_accs) / len(test_accs)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from torchinfo import summary\n",
    "summary(model, verbose=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "50ccc516328d5b564b2da3ee1dd645a78b56fd0f0e8585996496188dec9b39eb"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit ('NLP': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}