{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch\n",
    "from config import conf\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Adam\n",
    "from transformers import DistilBertTokenizerFast, DistilBertForQuestionAnswering\n",
    "from tqdm import tqdm\n",
    "from dataset import SquadDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')\n",
    "dataset = SquadDataset.from_json(conf['DATASET_FILE'], tokenizer)\n",
    "train_dataset, val_dataset = dataset.train_val_split(conf['TRAIN_RATIO'])\n",
    "\n",
    "model = DistilBertForQuestionAnswering.from_pretrained('distilbert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(pred: torch.Tensor, true: torch.Tensor) -> float:\n",
    "    assert len(pred) == len(true)\n",
    "    return ((start_pred == start_true).sum() / len(start_pred)).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "model.to(device)\n",
    "\n",
    "opt = Adam(model.parameters(), lr=5e-5)\n",
    "train_loader = DataLoader(train_dataset, batch_size=conf['BATCH_SIZE'], shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=conf['BATCH_SIZE'])\n",
    "\n",
    "for epoch in range(conf['N_EPOCHS']):\n",
    "    # ================================ TRAINING ================================\n",
    "    model.train()\n",
    "\n",
    "    train_losses = []\n",
    "    train_accs = []\n",
    "\n",
    "    train_iter = tqdm(train_loader)\n",
    "    train_iter.set_description(f'Epoch {epoch}')\n",
    "    \n",
    "    for train_batch in train_iter:\n",
    "        input_ids = train_batch['input_ids'].to(device)\n",
    "        attention_mask = train_batch['attention_mask'].to(device)\n",
    "        start_true = train_batch['start_positions'].to(device)\n",
    "        end_true = train_batch['end_positions'].to(device)\n",
    "\n",
    "        outputs = model(input_ids, \n",
    "                        attention_mask=attention_mask,\n",
    "                        start_positions=start_true,\n",
    "                        end_positions=end_true)\n",
    "        start_pred = torch.argmax(outputs['start_logits'], dim=1)\n",
    "        end_pred = torch.argmax(outputs['end_logits'], dim=1)\n",
    "\n",
    "        loss = outputs['loss']\n",
    "        start_acc = compute_accuracy(start_pred, start_true)\n",
    "        end_acc = compute_accuracy(end_pred, end_true)\n",
    "\n",
    "        train_iter.set_postfix(loss=loss.item(), \n",
    "                               acc=(start_acc + end_acc) / 2)\n",
    "        \n",
    "        train_losses.append(loss.item())\n",
    "        train_accs.append(start_acc)\n",
    "        train_accs.append(end_acc)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "\n",
    "    # =============================== VALIDATION ===============================\n",
    "    model.eval()\n",
    "    \n",
    "    val_losses = []\n",
    "    val_accs = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for val_batch in val_loader:\n",
    "            input_ids = val_batch['input_ids'].to(device)\n",
    "            attention_mask = val_batch['attention_mask'].to(device)\n",
    "            start_true = val_batch['start_positions'].to(device)\n",
    "            end_true = val_batch['end_positions'].to(device)\n",
    "            \n",
    "            outputs = model(input_ids, attention_mask=attention_mask)\n",
    "            start_pred = torch.argmax(outputs['start_logits'], dim=1)\n",
    "            end_pred = torch.argmax(outputs['end_logits'], dim=1)\n",
    "\n",
    "            val_losses.append(outputs['loss'])\n",
    "            val_accs.append(compute_accuracy(start_pred, start_true))\n",
    "            val_accs.append(compute_accuracy(end_pred, end_true))\n",
    "    \n",
    "    train_iter.set_postfix(loss=sum(train_losses) / len(train_losses),\n",
    "                           acc=sum(train_accs) / len(train_accs),\n",
    "                           val_loss=sum(val_losses) / len(val_losses),\n",
    "                           val_acc=sum(val_accs) / len(val_accs))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
